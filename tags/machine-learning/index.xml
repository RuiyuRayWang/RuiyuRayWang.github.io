<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Karmotrine Dream</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Karmotrine Dream</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Aug 2022 21:50:00 +0800</lastBuildDate><atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Install Alphafold2 Docker Version (II)</title>
      <link>/post/setup_af2_ii/</link>
      <pubDate>Fri, 19 Aug 2022 21:50:00 +0800</pubDate>
      
      <guid>/post/setup_af2_ii/</guid>
      <description>https://github.com/deepmind/alphafold
Running AlphaFold The simplest way to run AlphaFold is using the provided Docker script. This was tested on Google Cloud with a machine using the nvidia-gpu-cloud-image with 12 vCPUs, 85 GB of RAM, a 100 GB boot disk, the databases on an additional 3 TB disk, and an A100 GPU.
 Clone this repository and cd into it.  (base) luolab@luolab-Z10PE-D16-WS:~/GITHUB_REPO$ git clone https://github.com/deepmind/alphafold.git Cloning into &#39;alphafold&#39;... remote: Enumerating objects: 569, done.</description>
    </item>
    
    <item>
      <title>Install Alphafold2 Docker Version (I)</title>
      <link>/post/setup_af2_i/</link>
      <pubDate>Fri, 19 Aug 2022 20:41:29 +0800</pubDate>
      
      <guid>/post/setup_af2_i/</guid>
      <description>https://github.com/deepmind/alphafold
First time setup You will need a machine running Linux, AlphaFold does not support other operating systems.
The following steps are required in order to run AlphaFold:
 Install Docker.  Install NVIDIA Container Toolkit for GPU support. Setup running Docker as a non-root user.   Download genetic databases (see below). Download model parameters (see below). Check that AlphaFold will be able to use a GPU by running:  docker run --rm --gpus all nvidia/cuda:11.</description>
    </item>
    
    <item>
      <title>Pytorch: End of Agony</title>
      <link>/post/pytorch-end-of-agony/</link>
      <pubDate>Sat, 18 Jun 2022 15:44:29 +0800</pubDate>
      
      <guid>/post/pytorch-end-of-agony/</guid>
      <description>The agonizing days of building everything from scratch (NVIDIA driver, CUDA, cuDNN) is over.
Don&amp;rsquo;t have to spend time on
CUDA documentaion,
or building
Tensorflow：多版本部署、系统配置与版本切换.
Now, use PyTorch, and you will be amazed at ease of building a GPU capable meachine learning model with neural network.
The PyTorch binaries include the CUDA and cuDNN libraries.
How to check if torch uses cuDNN</description>
    </item>
    
    <item>
      <title>The Bitter Lesson</title>
      <link>/post/the_bitter_lesson/</link>
      <pubDate>Fri, 27 May 2022 09:21:08 +0800</pubDate>
      
      <guid>/post/the_bitter_lesson/</guid>
      <description>Richard Sutton, the reknowned computer scientist, author of the AI bible: &amp;lsquo;Reinforcement Learning&amp;rsquo;, wrote this essay three years after Alphago beat Lee Sedol.
 http://www.incompleteideas.net/IncIdeas/BitterLesson.html
The article was originally written for AI researches, but the idea can be extrapolated to other fields.
 Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available.</description>
    </item>
    
    <item>
      <title>Tensorflow：多版本部署、系统配置与版本切换</title>
      <link>/post/build-tensorflow/</link>
      <pubDate>Sun, 05 Dec 2021 22:57:25 +0800</pubDate>
      
      <guid>/post/build-tensorflow/</guid>
      <description>Building Environments for Cellassign and CellBLAST with multiple Tensorflow (GPU) Versions on Ubuntu As promised, I will write about my experience with installing tensorflow.
Why did I ever have to build Tensorflow myself?
The reason is that I was trying to use two tools: cellassign and Cell_BLAST, but they depend on different tensorflow versions. To make them both work, I used the following build strategy that allows different Tensorflow versions installed and run in separate conda environments.</description>
    </item>
    
  </channel>
</rss>
